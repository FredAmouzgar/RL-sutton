{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Exercise 2.11](images/Exercise2.11-Sutton.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Bandit:\n",
    "    \n",
    "    def __init__(self, mu = 1, k = 10):\n",
    "        \"\"\"\n",
    "        By default creates an array of size k and mean of 1 which represents the q*(a).\n",
    "        \"\"\"\n",
    "        self.Qstars = np.ones(k) * mu\n",
    "        #print(self.Qstars)\n",
    "        \n",
    "    def __step(self):\n",
    "        for i in range(0, len(self.Qstars)):\n",
    "            self.Qstars[i] += np.random.normal(0, 0.01)\n",
    "        #print(self.Qstars)\n",
    "            \n",
    "    def pull_a_bandit(self, lever):\n",
    "        if lever < len(self.Qstars) and lever >=0:\n",
    "            reward = np.random.normal(self.Qstars[lever], 1)\n",
    "            self.__step()\n",
    "            return reward\n",
    "        else:\n",
    "            raise Exception(f\"Number {lever} out of range\")\n",
    "            \n",
    "    def print_bandit_content(self):\n",
    "        print(self.Qstars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bandit_Agent:\n",
    "    \n",
    "    def __init__(self, bandit):\n",
    "        self.action_values = np.zeros(10) # Q(a)\n",
    "        self.counts = np.zeros(10) # N(a)\n",
    "        self.iteration_number = 0\n",
    "        self.total_reward = 0\n",
    "        self.bandit = bandit\n",
    "        \n",
    "    def greedy_update(self):\n",
    "        self.iteration_number += 1\n",
    "        action_index = np.argmax(self.action_values) # Choose the best action\n",
    "        reward = self.bandit.pull_a_bandit(action_index) # Get the reward from the bandit\n",
    "        self.total_reward += reward # Add the reward to the accumulated reward\n",
    "        self.counts[action_index] += 1 # Increment the number of that action\n",
    "        self.action_values[action_index] = self.action_values[action_index] + (reward - self.action_values[action_index])/self.counts[action_index]\n",
    "        return self.total_reward/self.iteration_number\n",
    "    \n",
    "    def epsilon_greedy_update(self, epsilon=0.01):\n",
    "        self.iteration_number += 1\n",
    "        if np.random.rand() > epsilon:\n",
    "            action_index = np.argmax(self.action_values) # Choose the best action\n",
    "        else:\n",
    "            action_index = np.random.randint(0,10) # Choose a random action\n",
    "        reward = self.bandit.pull_a_bandit(action_index) # Get the reward from the bandit\n",
    "        self.total_reward += reward # Add the reward to the accumulated reward\n",
    "        self.counts[action_index] += 1 # Increment the number of that action\n",
    "        self.action_values[action_index] = self.action_values[action_index] + (reward - self.action_values[action_index])/self.counts[action_index]\n",
    "        return self.total_reward/self.iteration_number\n",
    "    \n",
    "    def epsilon_greedy_constant_update(self, epsilon=0.1, alpha=0.1):\n",
    "        self.iteration_number += 1\n",
    "        if np.random.rand() > epsilon:\n",
    "            action_index = np.argmax(self.action_values) # Choose the best action\n",
    "        else:\n",
    "            action_index = np.random.randint(0,10) # Choose a random action\n",
    "        reward = self.bandit.pull_a_bandit(action_index) # Get the reward from the bandit\n",
    "        self.total_reward += reward # Add the reward to the accumulated reward\n",
    "        self.counts[action_index] += 1 # Increment the number of that action\n",
    "        self.action_values[action_index] = self.action_values[action_index] + alpha * (reward - self.action_values[action_index])\n",
    "        return self.total_reward/self.iteration_number\n",
    "        \n",
    "    def obj_print(self):\n",
    "        print(f\"{self.action_values},avg_reward={self.total_reward/self.iteration_number},best_action={self.best_action()}\")\n",
    "        \n",
    "    def best_action(self):\n",
    "        return np.max(self.action_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_constant_update_bandit = Bandit()\n",
    "agent_constant_update = Bandit_Agent(bandit = agent_constant_update_bandit)\n",
    "\n",
    "EPOCHS = 200000\n",
    "epochsaverage_last_rewards =  \n",
    "\n",
    "greedy_rewards = np.zeros(EPOCHS)\n",
    "epsilon_greedy_rewards = np.zeros(EPOCHS)\n",
    "epsilon_greedy_constant_rewards = np.zeros(EPOCHS)\n",
    "for i in range(0,EPOCHS):\n",
    "    greedy_rewards[i] = agent_greedy.greedy_update()\n",
    "    epsilon_greedy_rewards[i] = agent_epsilon.epsilon_greedy_update(epsilon=0.1)\n",
    "    epsilon_greedy_constant_rewards[i] = agent_constant_update.epsilon_greedy_constant_update(epsilon=0.1, alpha=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
