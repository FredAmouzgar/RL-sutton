{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Walk for n-step TD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here's how you can run a random walk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 1, True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from time import sleep\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from randomwalk import RandomWalk\n",
    "\n",
    "%matplotlib inline\n",
    "env = RandomWalk(non_terminal_states=5, init_state=3)\n",
    "\n",
    "for i in range(100):\n",
    "    # a = np.random.choice(['left', 'right'])\n",
    "    # res = env.step(a)\n",
    "    res = env.random_step()\n",
    "    s_, r, done = res\n",
    "    print(res)\n",
    "    env.render()\n",
    "    sleep(0.1)\n",
    "    if done:\n",
    "        break\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n': 7, 'Terminal states': 2, 'Non-terminal states': 5}\n",
      "7\n",
      "\n",
      "['left', 'right']\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space)\n",
    "print(env.observation_space[\"n\"])\n",
    "print()\n",
    "print(env.action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n-step TD (Policy is a uniform distribution)\n",
    "<img src=\"images/n-stepTD.PNG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class N_StepTD:\n",
    "    def __init__(self, states_number, actions, alpha=0.5, gamma=0.95, n_step=5):\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.states_number = states_number\n",
    "        self.actions = actions\n",
    "        self.V = np.zeros(states_n) + 0.5 # Initial Value is 0.5\n",
    "        self.new_a = None\n",
    "        \n",
    "        #\n",
    "        self.steps_memory = []\n",
    "        self.n_step = n_step\n",
    "        self.current_step = 0\n",
    "    \n",
    "    def act(self, state):\n",
    "        act = np.random.choice(self.actions)\n",
    "        return act\n",
    "    \n",
    "    def update(self,new_s,r,done):\n",
    "        self.steps_memory.append({\"s_\": new_s, \"r\": r, \"done\": done})\n",
    "        self.current_step += 1\n",
    "        \n",
    "        if self.current_step >= self.n_step - 1:\n",
    "            self.TD_update()\n",
    "    \n",
    "    def TD_update(self):\n",
    "        G = 0\n",
    "        discount = 1\n",
    "        for step in self.steps_memory[(self.current_step - self.n_step + 1) + 1:]:\n",
    "            G += discount * step['r']\n",
    "            discount *= self.gamma\n",
    "        last_step = self.steps_memory[-1]\n",
    "        G += discount * (1 - float(last_step['done'])) * self.V[last_stept['s_']]\n",
    "        state_to_update = self.steps_memory[self.current_step - self.n_step + 1]\n",
    "        self.V[state_to_update['s_']] += self.alpha * (G - self.V[state_to_update['s_']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from randomwalk import RandomWalk\n",
    "\n",
    "%matplotlib inline\n",
    "env = RandomWalk(non_terminal_states=19, init_state=3)\n",
    "td_agent = N_StepTD(states_number=env.observation_space[\"n\"], actions=env.action_space)\n",
    "\n",
    "steps = []\n",
    "returns = []\n",
    "for episode in range(10):\n",
    "    env.reset()\n",
    "    state = env.state\n",
    "    action = agent.act(state)\n",
    "    done = False\n",
    "    step_n = 0\n",
    "    return_episode = 0\n",
    "    while not done:\n",
    "        new_state,reward,done = env.step(action)\n",
    "        return_episode += reward\n",
    "        new_action = agent.update(new_state,reward,state,action,done)\n",
    "        state, action = new_state, new_action\n",
    "        step_n += 1\n",
    "        if done:\n",
    "            steps.append(step_n)\n",
    "            returns.append(return_episode)\n",
    "            clear_output(wait=True)\n",
    "            plt.title(\"Steps:\" + str(step_n) + \" Return:\"+str(return_episode))\n",
    "            plt.plot(list(range(len(steps))),steps)\n",
    "            plt.plot(list(range(len(steps))),returns)\n",
    "            plt.legend([\"Steps\", \"Returns\"])\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
