{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Sutton-p76-GridWorld.png\" width=\"800px\" height=\"400px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GridWorld:\n",
    "    def __init__(self):\n",
    "        # self.worldValues = np.random.rand(4,4) * 5\n",
    "        self.worldValues = np.zeros((4,4))\n",
    "        self.worldValues[0,0] = 0\n",
    "        self.worldValues[3,3] = 0\n",
    "        self.currentState = int(np.random.rand()*8 + 2) ## The current state is randomly generated, but the world knows where you are\n",
    "        self.actions = [0, 1, 2, 3]\n",
    "        self.actionNames = {0:\"up\", 1:\"down\", 2:\"left\", 3:\"right\"}\n",
    "        \n",
    "    def step(self,action):\n",
    "        self.currentState = GridWorld.move(self.currentState, action)\n",
    "        if self.currentState == 0 or self.currentState == 15:\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = -1\n",
    "        return self.currentState, reward\n",
    "    def get_value(self, state_no):\n",
    "        x, y = GridWorld.state_coordinates(state_no)\n",
    "        return self.worldValues[x,y]\n",
    "    def set_value(self, state_no, value):\n",
    "        x, y = GridWorld.state_coordinates(state_no)\n",
    "        self.worldValues[x,y] = value\n",
    "    \n",
    "    @staticmethod\n",
    "    def general_step(state, action):\n",
    "        new_state = GridWorld.move(state, action)\n",
    "        if new_state == 0 or new_state == 15:\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = -1\n",
    "        return new_state, reward\n",
    "    @staticmethod\n",
    "    def state_nunmber(x,y):\n",
    "        position = x*4 + y\n",
    "        return position\n",
    "    @staticmethod\n",
    "    def state_coordinates(number):\n",
    "        y = number % 4\n",
    "        x = number // 4\n",
    "        return (x,y)\n",
    "    @staticmethod\n",
    "    def move(s,a):\n",
    "        x, y = GridWorld.state_coordinates(s)\n",
    "        if x == 0 and a == 0: # Changing the x-coordinates\n",
    "            x = 0\n",
    "        elif x == 3 and a == 1:\n",
    "            x = 3\n",
    "        else:\n",
    "            if a == 0:\n",
    "                x = x - 1\n",
    "            elif a == 1:\n",
    "                x = x + 1\n",
    "        \n",
    "        if y == 0 and a == 2: # Changing the y-coordinates\n",
    "            y = 0\n",
    "        elif y == 3 and a == 3:\n",
    "            y = 3\n",
    "        else:\n",
    "            if a == 2:\n",
    "                y = y - 1\n",
    "            elif a == 3:\n",
    "                y = y + 1\n",
    "        return GridWorld.state_nunmber(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world = GridWorld()\n",
    "world.worldValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GridWorld.general_step(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def action(self): ## Implementing the equiprobable policy\n",
    "        return np.random.randint(4)\n",
    "    def policy(self):\n",
    "        return 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Sutton-PolicyEvaluation.png\" width=\"800px\" height=\"400px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 0\n",
      "--------\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "K = 1\n",
      "--------\n",
      "[[ 0.         -0.5        -1.125      -1.28125   ]\n",
      " [-0.5        -1.25       -1.59375    -1.71875   ]\n",
      " [-1.125      -1.59375    -1.796875   -1.37890625]\n",
      " [-1.28125    -1.71875    -1.37890625  0.        ]]\n",
      "K = 2\n",
      "--------\n",
      "[[ 0.         -1.21875    -2.3046875  -2.64648438]\n",
      " [-1.21875    -2.40625    -3.05664062 -3.20019531]\n",
      " [-2.3046875  -3.05664062 -3.21777344 -2.44921875]\n",
      " [-2.64648438 -3.20019531 -2.44921875  0.        ]]\n",
      "K = 3\n",
      "--------\n",
      "[[ 0.         -1.98242188 -3.49755859 -3.99768066]\n",
      " [-1.98242188 -3.51953125 -4.35876465 -4.50146484]\n",
      " [-3.49755859 -4.35876465 -4.4039917  -3.33866882]\n",
      " [-3.99768066 -4.50146484 -3.33866882  0.        ]]\n",
      "K = 10\n",
      "--------\n",
      "[[  0.          -6.47871183 -10.06161583 -11.26202333]\n",
      " [ -6.47871183  -9.22317257 -10.64122233 -10.72526226]\n",
      " [-10.06161583 -10.64122233  -9.78987681  -7.3634176 ]\n",
      " [-11.26202333 -10.72526226  -7.3634176    0.        ]]\n",
      "Number of main loops, Last K = 271\n",
      "--------\n",
      "[[  0. -12. -18. -20.]\n",
      " [-12. -16. -18. -18.]\n",
      " [-18. -18. -16. -12.]\n",
      " [-20. -18. -12.   0.]]\n"
     ]
    }
   ],
   "source": [
    "def areDeltasLargerThanTheta(d, t, while_counter):\n",
    "    if while_counter < 2: ## Turning the while to a do..while loop\n",
    "        return True\n",
    "    for i in range(d.shape[0]):\n",
    "        if abs(d[i]) > abs(t):\n",
    "            return True\n",
    "    return False\n",
    "#def iterative_policy_evaluation():\n",
    "if __name__ == \"__main__\":\n",
    "    world = GridWorld()\n",
    "    agent = Agent()\n",
    "    theta = 1e-10 ## Every element in delta will be compared to this value\n",
    "    deltas = np.zeros(15) # [0, 0 ...]\n",
    "    while_count = 0\n",
    "    while areDeltasLargerThanTheta(deltas, theta, while_count):\n",
    "        ################\n",
    "        k = while_count\n",
    "        if k == 0 or k == 1 or k == 2 or k == 3 or k == 10:\n",
    "            print(\"K =\", k)\n",
    "            print(\"--------\")\n",
    "            print(world.worldValues)\n",
    "        ################\n",
    "        deltas = np.zeros(15) # [0, 0 ...] Zeroing deltas every time\n",
    "        while_count+=1\n",
    "        for state in range(1,15):\n",
    "            v = world.get_value(state) ## v <- V(s)\n",
    "            new_v = 0\n",
    "            for action in range(len(world.actions)):                   ## Generating the \\sum \\pi(a|s)\n",
    "            #This is an undicounted update (no \\gamma)\n",
    "                new_s, r = GridWorld.general_step(state, action)       ## p(s',r | s,a) \n",
    "                new_v += agent.policy() * (r + world.get_value(new_s)) ## Adding the value of every action to the value of the state\n",
    "            world.set_value(state, new_v)                              ## V(s) <- Expression\n",
    "            deltas[state] = max(deltas[state], abs(new_v - v))         ## \\delta <- max(\\delta, |v - V(s)|)\n",
    "print(\"Number of main loops, Last K =\", while_count)\n",
    "print(\"--------\")\n",
    "print(world.worldValues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/GridWorld_values.jpeg\" width=\"400px\" height=\"800px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 6.05098194e-11, 8.69917471e-11, 9.57491864e-11,\n",
       "       6.05098194e-11, 7.42552686e-11, 8.06252842e-11, 7.97015787e-11,\n",
       "       8.69917471e-11, 8.06252842e-11, 6.80309142e-11, 5.07931475e-11,\n",
       "       9.57491864e-11, 7.97015787e-11, 5.07931475e-11])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deltas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
